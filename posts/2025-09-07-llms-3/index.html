






<!doctype html>
<html
  lang="en-us"
  dir="ltr"
  class="scroll-smooth"
  data-default-appearance="dark"
  data-auto-appearance="true"
><head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta name="theme-color" content="#FFFFFF" />
  
  <title>Large Language Models, pt. 3: Context &middot; Eric&#39;s Web.site</title>
    <meta name="title" content="Large Language Models, pt. 3: Context &middot; Eric&#39;s Web.site" />
  
  
  
  
  
  <script
    type="text/javascript"
    src="http://bartolomeo.home:1313/js/appearance.min.8a082f81b27f3cb2ee528df0b0bdc39787034cf2cc34d4669fbc9977c929023c.js"
    integrity="sha256-iggvgbJ/PLLuUo3wsL3Dl4cDTPLMNNRmn7yZd8kpAjw="
  ></script>
  
  
  
  
  
  
  
  
  <link
    type="text/css"
    rel="stylesheet"
    href="http://bartolomeo.home:1313/css/main.bundle.min.8363fdb90097634558e4c060565c2caefbddbf21152432d1b5ca1f55adca4e75.css"
    integrity="sha256-g2P9uQCXY0VY5MBgVlwsrvvdvyEVJDLRtcofVa3KTnU="
  />
  
  
  
  
  
  
  
  <meta
    name="description"
    content="
      
        This is part of a multi-part series of essays on LLMs. 
      
    Start from the beginning or view all posts?
For the LLM user, managing &ldquo;context&rdquo; is the single most important part of using an LLM.
Context #Returning to how LLMs work, the context is all of the data fed in. This will include all prompts configured by the user, the prompts configured by the administrator of the LLM, and all of the chat messages that have occurred in the conversation, including the LLM&rsquo;s own chats. All of this context is fed in when the LLM generates its next bit of text. Every word in the context has some influence on what comes next; some more more important than others, but all of them have an effect. This means that cultivating context is everything, in terms of what kind of output the LLM produces.
      
    "
  />
  
  
  
  
    <link rel="canonical" href="http://bartolomeo.home:1313/posts/2025-09-07-llms-3/" />
  
  
  
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png" />
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png" />
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png" />
    <link rel="manifest" href="/site.webmanifest" />
  
  
  
  
  
  
  
  
  <meta property="og:url" content="http://bartolomeo.home:1313/posts/2025-09-07-llms-3/">
  <meta property="og:site_name" content="Eric&#39;s Web.site">
  <meta property="og:title" content="Large Language Models, pt. 3: Context">
  <meta property="og:description" content="This is part of a multi-part series of essays on LLMs. Start from the beginning or view all posts?
For the LLM user, managing “context” is the single most important part of using an LLM.
Context #Returning to how LLMs work, the context is all of the data fed in. This will include all prompts configured by the user, the prompts configured by the administrator of the LLM, and all of the chat messages that have occurred in the conversation, including the LLM’s own chats. All of this context is fed in when the LLM generates its next bit of text. Every word in the context has some influence on what comes next; some more more important than others, but all of them have an effect. This means that cultivating context is everything, in terms of what kind of output the LLM produces.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-09-04T15:09:11-05:00">
    <meta property="article:modified_time" content="2025-09-04T15:09:11-05:00">

  
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Large Language Models, pt. 3: Context">
  <meta name="twitter:description" content="This is part of a multi-part series of essays on LLMs. Start from the beginning or view all posts?
For the LLM user, managing “context” is the single most important part of using an LLM.
Context #Returning to how LLMs work, the context is all of the data fed in. This will include all prompts configured by the user, the prompts configured by the administrator of the LLM, and all of the chat messages that have occurred in the conversation, including the LLM’s own chats. All of this context is fed in when the LLM generates its next bit of text. Every word in the context has some influence on what comes next; some more more important than others, but all of them have an effect. This means that cultivating context is everything, in terms of what kind of output the LLM produces.">

  
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Article",
    "articleSection": "Posts",
    "name": "Large Language Models, pt. 3: Context",
    "headline": "Large Language Models, pt. 3: Context",
    
    "abstract": "\u003cp\u003eThis is part of a multi-part series of essays on LLMs. \n      \n    \u003ca href=\u0022http:\/\/bartolomeo.home:1313\/posts\/2025-09-05-llms-1\/\u0022\u003eStart from the beginning\u003c\/a\u003e or \u003ca href=\u0022\/categories\/LLMs\u0022\u003eview all posts\u003c\/a\u003e?\u003c\/p\u003e\n\u003cp\u003eFor the LLM user, managing \u0026ldquo;context\u0026rdquo; is the single most important part of using an LLM.\u003c\/p\u003e\n\u003ch1 id=\u0022context\u0022 class=\u0022relative group\u0022\u003eContext \u003cspan class=\u0022absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100\u0022\u003e\u003ca class=\u0022group-hover:text-primary-300 dark:group-hover:text-neutral-700\u0022 style=\u0022text-decoration-line: none !important;\u0022 href=\u0022#context\u0022 aria-label=\u0022Anchor\u0022\u003e#\u003c\/a\u003e\u003c\/span\u003e\u003c\/h1\u003e\u003cp\u003eReturning to how LLMs work, the context is all of the data fed in. This will include all prompts configured by the user, the prompts configured by the administrator of the LLM, and all of the chat messages that have occurred in the conversation, including the LLM\u0026rsquo;s own chats. All of this context is fed in when the LLM generates its next bit of text. Every word in the context has some influence on what comes next; some more more important than others, but all of them have \u003cem\u003ean effect\u003c\/em\u003e. This means that cultivating context is \u003cem\u003eeverything\u003c\/em\u003e, in terms of what kind of output the LLM produces.\u003c\/p\u003e",
    "inLanguage": "en-us",
    "url" : "http:\/\/bartolomeo.home:1313\/posts\/2025-09-07-llms-3\/",
    "author" : {
      "@type": "Person",
      "name": "Eric Miller"
    },
    "copyrightYear": "2025",
    "dateCreated": "2025-09-04T15:09:11-05:00",
    "datePublished": "2025-09-04T15:09:11-05:00",
    
    "dateModified": "2025-09-04T15:09:11-05:00",
    
    "keywords": ["llms","opinion","essay"],
    
    "mainEntityOfPage": "true",
    "wordCount": "2078"
  }
  </script>
    
    <script type="application/ld+json">
    {
   "@context": "https://schema.org",
   "@type": "BreadcrumbList",
   "itemListElement": [
     {
       "@type": "ListItem",
       "item": "http://bartolomeo.home:1313/",
       "name": "Index",
       "position": 1
     },
     {
       "@type": "ListItem",
       "item": "http://bartolomeo.home:1313/posts/",
       "name": "Posts",
       "position": 2
     },
     {
       "@type": "ListItem",
       "name": "Large Language Models, Pt. 3 Context",
       "position": 3
     }
   ]
 }
  </script>

  
  
    <meta name="author" content="Eric Miller" />
  
  
    
      <link href="https://github.com/sosheskaz/" rel="me" />
    
      <link href="https://www.linkedin.com/in/eric-miller/" rel="me" />
    
  
  
  







  
  

  
  
</head>
<body
    class="m-auto flex h-screen max-w-7xl flex-col bg-neutral px-6 text-lg leading-7 text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32"
  >
    <div id="the-top" class="absolute flex self-center">
      <a
        class="-translate-y-8 rounded-b-lg bg-primary-200 px-3 py-1 text-sm focus:translate-y-0 dark:bg-neutral-600"
        href="#main-content"
        ><span class="pe-2 font-bold text-primary-600 dark:text-primary-400">&darr;</span
        >Skip to main content</a
      >
    </div>
    
    
      <header class="py-6 font-semibold text-neutral-900 dark:text-neutral sm:py-10 print:hidden">
  <nav class="flex items-start justify-between sm:items-center">
    
    <div class="flex flex-row items-center">
      
  <a
    class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2"
    rel="me"
    href="/"
    >Eric&rsquo;s Web.site</a
  >

    </div>
    
    
      <ul class="flex list-none flex-col text-end sm:flex-row">
        
          
            
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5">
              
                <a
                  href="/posts/"
                  title="Posts"
                  
                  ><span
                      class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                      >All Posts</span
                    >
                  </a
                >
              
            </li>
          
            
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5">
              
                <a
                  href="/categories/"
                  title="Categories"
                  
                  ><span
                      class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                      >Categories</span
                    >
                  </a
                >
              
            </li>
          
            
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5">
              
                <a
                  href="/index.xml"
                  title=""
                  
                  ><span
                      class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                      >RSS</span
                    >
                  </a
                >
              
            </li>
          
            
            <li class="group mb-1 sm:mb-0 sm:me-7 sm:last:me-0.5">
              
                <a
                  href="/profile/"
                  title="About Me"
                  
                  ><span
                      class="decoration-primary-500 group-hover:underline group-hover:decoration-2 group-hover:underline-offset-2"
                      >About</span
                    >
                  </a
                >
              
            </li>
          
          
        
      </ul>
    
  </nav>
</header>

    
    <div class="relative flex grow flex-col">
      <main id="main-content" class="grow">
        
  <article>
    <header class="max-w-prose">
      
        <ol class="text-sm text-neutral-500 dark:text-neutral-400 print:hidden">
  
  
    
  
    
  
  <li class="hidden inline">
    <a
      class="dark:underline-neutral-600 decoration-neutral-300 hover:underline"
      href="http://bartolomeo.home:1313/"
      >Index</a
    ><span class="px-1 text-primary-500">/</span>
  </li>

  
  <li class=" inline">
    <a
      class="dark:underline-neutral-600 decoration-neutral-300 hover:underline"
      href="http://bartolomeo.home:1313/posts/"
      >Posts</a
    ><span class="px-1 text-primary-500">/</span>
  </li>

  
  <li class="hidden inline">
    <a
      class="dark:underline-neutral-600 decoration-neutral-300 hover:underline"
      href="http://bartolomeo.home:1313/posts/2025-09-07-llms-3/"
      >Large Language Models, pt. 3: Context</a
    ><span class="px-1 text-primary-500">/</span>
  </li>

</ol>


      
      <h1 class="mb-8 mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">
        Large Language Models, pt. 3: Context
      </h1>
      
        <div class="mb-10 text-base text-neutral-500 dark:text-neutral-400 print:hidden">
          





  
  



  

  
  
    
  

  

  

  
    
  

  


  <div class="flex flex-row flex-wrap items-center">
    
    
      <time datetime="2025-09-04 15:09:11 -0500 CDT">September 4, 2025</time><span class="px-2 text-primary-500">&middot;</span><span title="Reading time">10 mins</span>
    

    
    
      <span class="ps-2"><span class="flex">
  <span
    class="ms-1 rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400"
  >
    Draft
  </span>
</span>
</span>
    
  </div>

  
  


        </div>
      
      
    </header>
    <section class="prose mt-0 flex max-w-full flex-col dark:prose-invert lg:flex-row">
      
      <div class="min-h-0 min-w-0 max-w-prose grow">
        <p>This is part of a multi-part series of essays on LLMs. 
      
    <a href="http://bartolomeo.home:1313/posts/2025-09-05-llms-1/">Start from the beginning</a> or <a href="/categories/LLMs">view all posts</a>?</p>
<p>For the LLM user, managing &ldquo;context&rdquo; is the single most important part of using an LLM.</p>
<h1 id="context" class="relative group">Context <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#context" aria-label="Anchor">#</a></span></h1><p>Returning to how LLMs work, the context is all of the data fed in. This will include all prompts configured by the user, the prompts configured by the administrator of the LLM, and all of the chat messages that have occurred in the conversation, including the LLM&rsquo;s own chats. All of this context is fed in when the LLM generates its next bit of text. Every word in the context has some influence on what comes next; some more more important than others, but all of them have <em>an effect</em>. This means that cultivating context is <em>everything</em>, in terms of what kind of output the LLM produces.</p>
<p>However, this can be a double-edged sword. A first instinct can be to include as much relevant information as possible in the prompts, in order to make all of the information available, for the LLM to make the best-informed decisions. However, it has been observed that LLMs get dumber when they have particularly long context. As there&rsquo;s more context, the LLM struggles to differentiate what is important, and what is not. As context gets longer, the model is more prone to making mistakes about relevance, that appear like logical errors. Often, an LLM may vastly overestimate the importance of a bit of context, or may vastly underestimate the importance of a bit of context.</p>
<p>This means that context management for LLMs is a balancing act. The more high-quality, relevant information we have, the better the output. However, the more context we add, the less accurate the model will be for all of the context. The goal, then, is to keep context that is relevant, and informationally dense. Maintaining &ldquo;focus&rdquo; in the context is paramount. Relatedly, we can use certain characteristics of LLMs (they tend to place more importance on more recent context) in order to shape the output, and truncate or delete chats once they get too long, and move to new chats. There are many controls to operate here, in order to optimize this balance.</p>
<p>LLMs are also influenced significantly by past conversation, by both the user and by the LLM. One of the clearest places I&rsquo;ve seen this is that if a LLM refused to perform a task for safety reasons earlier in the conversation, it&rsquo;s much more likely to refuse subsequent tasks than it would be otherwise. Relatedly, an off-handed comment, or a change in writing style, will influence the style that an LLM uses going forward, and alters its inference. LLMs also can read <em>tone</em>, whether or not that tone was intended, and they consider that tone when constructing their output. This is all to say: every little bit of context <em>matters</em> in terms of what you get out of a LLM. The ideal is that <em>every bit of context</em> should be there for the sole purpose of getting a better result out of the LLM, one way or another.</p>
<p>Relatedly, the phrasing of messages is absolutely essential to get good output. Subtle phrasing cues may signal to the LLM &ldquo;the kind of output you want&rdquo;, and not necessarily &ldquo;the best output&rdquo;. Leading questions, for example, increase the likelihood of hallucination, and will generally be more likely to give the answer that &ldquo;it thinks you want&rdquo;. Strategically hiding your goals until later in the conversation can be important, to make sure that the early conversation does not have the well poisoned by the user&rsquo;s biases or intent.</p>
<h2 id="system-prompts" class="relative group">System Prompts <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#system-prompts" aria-label="Anchor">#</a></span></h2><p>Open LLMs generally have an option for a &ldquo;system prompt&rdquo; which is present in every conversation, held in an important place in context. OpenAI has similar functionality. This is a very useful tool for tuning LLMs, both for personal taste, and to get better results. Instructions can be placed here to universally alter the behavior, without constantly needing to ask for it. Some helpful bits I&rsquo;ve found are &ldquo;When asked for feedback or options, surface tradeoffs or risks as well&rdquo; and &ldquo;When relevant, ask sharp questions to help clarify strategy, uncover blind spots, or surface hidden assumptions&rdquo;, as examples. I use these to coach the LLM into being a bit more argumentative, and to avoid absolute statements. It makes it clear to the LLM that I want a nuanced discussion, not absolute statements, which in my experience makes it less prone to strong hallucinations, or getting stuck down a bad path.</p>
<h2 id="rag" class="relative group">RAG <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#rag" aria-label="Anchor">#</a></span></h2><p>RAG stands for &ldquo;retrieval-augmented generation&rdquo;. It is used to describe when an LLM does a search or call, to identify relevant information, and then to inject that data into its context, along with the user prompt, to make sure the model has access to all relevant information. This is an attempt to deal with these problems. It avoids pulling all of the data into the context for every message, allowing an individual message to have the context from the search, without dumping all of that data into the greater context of the conversation. It also allows it to have access to many documents, but to only pull the most relevant into context.</p>
<p>RAG is generally the preferred way to have a large knowledgebase available to an LLM. Contemporary RAG engines generally use vector databases, which allow an LLM to search based on the &ldquo;connectedness of the concepts&rdquo;. Where a traditional search might struggle to identify &ldquo;bread&rdquo; as a relevant part of a search for &ldquo;sandwich&rdquo;, a vector database could identify the relationships between the concepts, much like an LLM can, which allows it to identify conceptually adjacent pages when there are weaker associations. This makes it a powerful tool, getting around many of the problems of having &ldquo;too much context&rdquo;, while also pulling in relevant, high-quality, and factual data. It&rsquo;s also still fairly early days, and techniques are still being developed to improve the connection. Today, it can sometimes be off from what we desire.</p>
<h2 id="thinking" class="relative group">Thinking <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#thinking" aria-label="Anchor">#</a></span></h2><p>&ldquo;Thinking&rdquo; or &ldquo;reasoning&rdquo; are worth particular mention here. These are techniques popularized the last few years, that result from shaping the context of an LLM in order to perform functions meant to approximate reasoning. These essentially work (oversimplified) by giving the LLM a notepad, and allowing it to write down some notes before answering the question. This can allow the LLM to identify key facts, put those key facts next to each other, consider how they interact, and consider how it wants to structure that answer, before it starts writing output. In practice, this essentially injects a summary right before the message, that exists in context only for that message. This can be useful sometimes. I&rsquo;ve found this does best in situations with multiple variables, that interact in complex ways, or where the variables create complexities that benefit from creating an outline before the LLM constructs its final response.</p>
<p>However, it has been found in studies that &ldquo;thinking&rdquo; mode is a mixed bag. In the famous <a href="https://machinelearning.apple.com/research/illusion-of-thinking" target="_blank" rel="noreferrer">Apple Study</a>, they found that:</p>
<ul>
<li>In low-complexity tasks, non-reasoning models outperform reasoning models.</li>
<li>In medium-complexity tasks, reasoning models outperform non-reasoning models.</li>
<li>In high-complexity tasks, both kinds of models perform poorly.</li>
</ul>
<p>Remember: more context is only really helpful if it&rsquo;s informationally dense, and adds value. For tasks that are simple, &ldquo;thinking&rdquo; affords the model more opportunities to hallucinate, make mistakes, or misidentify the importance of a bit of information. This is informationally useful on deciding when to use &ldquo;thinking&rdquo; or &ldquo;non-thinking&rdquo; modes, but also in thinking about how mindfully shaping context can influence LLMs&rsquo; outputs.</p>
<h2 id="context-curation" class="relative group">Context Curation <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#context-curation" aria-label="Anchor">#</a></span></h2><p>A simpler and more pragmatic approach would be &ldquo;curation&rdquo;, where the user actively manages the context. This means constraining the output of the LLM to be focused on the task, and managing the facts directly. This is much of how I use LLMs. Considering one&rsquo;s tone, managing the facts present in the conversation, tightly instructing the LLM on expected output, and comprehensive use of prompts to shape behavior, are incredible and accessible tools to get the most out of LLMs. Discarding chats before they go on too long can keep the context clean and focused. Copy/paste can be quite powerful, as can RAG and other tools that facilitate factual lookups from trusted sources. LLMs are also quite good at summarization, and at identifying relevance, so LLMs themselves can be useful for the purposes of extracting important information from a chat in a dense and concise way.</p>
<p>Maintaining an individual task as a focused, single-task exercise, where excess messages are removed, is a valuable strategy. LLMs are also very capable of summarizing, so if a chat goes off the rails or goes too long, we can pull a set of facts together into a summary, and move the conversation into a different chat, where we focus on a different aspect. Maintaining many, focused chats generally works very well, as long as this is done carefully.</p>
<p>When interacting with LLMs programmatically, or in an agentic framework, I think this presents some interesting opportunities. Not all LLMs need to have the same conversation history. We can run LLMs in a multi-thread context, where a dedicated &ldquo;expert&rdquo; LLM has a curated context, and deals with the main &ldquo;conversation&rdquo; in a very limited fashion—answering questions, but not knowing why they were asked. I believe that this is going to become an important part of how LLMs are used, and I would predict that the &ldquo;simple conversation&rdquo; model that drives most chats we see today will eventually move to a &ldquo;multi-thread, multi-agent&rdquo; model, where specialized conversations are managed to specialize in certain areas of a task, and separated from the orchestration.</p>
<h2 id="questions" class="relative group">Questions <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#questions" aria-label="Anchor">#</a></span></h2><p>Questions are a powerful tool with LLMs.</p>
<p>A strategy I&rsquo;ve come to like for LLMs, is asking for a list of questions. Then, I will put those questions in a text document, and answer all of them. I may answer those questions in that chat, or simply open a new one, with a list of the facts we have assembled as a prologue, to minimize context use. This is useful because LLMs are quite good at figuring out &ldquo;what are the relevant pieces of information that we want to know for this purpose?&rdquo;, and it affords an opportunity for us to provide those answers, and allows us to enrich the context with hand-picked, relevant facts. While LLMs are bad at admitting that they don&rsquo;t know the answer to a question given to them, they are much better at identifying &ldquo;a list of relevant things that they don&rsquo;t know&rdquo;. This helps get ahead of that problem.</p>
<p>Relatedly, if a LLM identifies something as &ldquo;something it doesn&rsquo;t know&rdquo; in this way, then it is less likely to hallucinate a false answer later in the conversation. LLMs are designed to be consistent through the conversation to the extent possible, so if they see that they previously said they didn&rsquo;t know something, they are less likely to hallucinate an answer, because a hallucinated would contradict the context. Soliciting questions, in this way, can help the LLM set its own boundaries relatively well.</p>
<p>In a similar fashion, asking LLMs &ldquo;why?&rdquo; is a productive exercise. &ldquo;Why did you reply that way? Why did you say XYZ, what made you think it was important?&rdquo; It&rsquo;s important to know that the LLM&rsquo;s answers are not necessarily true. It&rsquo;s predicting the next token, and when it answers that question, it&rsquo;s just predicting the next token. They don&rsquo;t have thoughts, so there is no &ldquo;why&rdquo;. However: the LLM is trained to draw connections, and it has the same weights as it did when it answered the question, so it&rsquo;s generally able to construct an enlightening answer. It can give you hints about what in your prompt may be influencing it, and how. It can give you hints about what biases may be built into the LLM, or how you may adjust a prompt to get output more or less like that result in future.</p>
<h1 id="closing" class="relative group">Closing <span class="absolute top-0 w-6 transition-opacity opacity-0 -start-6 not-prose group-hover:opacity-100"><a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700" style="text-decoration-line: none !important;" href="#closing" aria-label="Anchor">#</a></span></h1><p>Actively consider what is in the context when you send a message to a LLM, and how you might shape that context to achieve better results. The shaping of context greatly affects the quality of the output, and there is a lot to be done there to achieve good results. Having this mindset, of almost constantly asking &ldquo;What is in the context? Is it relevant? Should anything be added?&rdquo; helps keep the user in control, and the LLM getting good results.</p>

      </div>
    </section>
    <footer class="max-w-prose pt-8 print:hidden">
      
  <div class="flex">
    
    
    
      
      
    
    <div class="place-self-center">
      
        <div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">
          Author
        </div>
        <div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">
          Eric Miller
        </div>
      
      
        <div class="text-sm text-neutral-700 dark:text-neutral-400">Software Engineer, Kuberneter</div>
      
      <div class="text-2xl sm:text-lg">
  <div class="flex flex-wrap text-neutral-400 dark:text-neutral-500">
    
      
        <a
          class="px-1 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400"
          style="will-change:transform;"
          href="https://github.com/sosheskaz/"
          target="_blank"
          aria-label="Github"
          rel="me noopener noreferrer"
          ><span class="icon relative inline-block px-1 align-text-bottom"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
</span></a
        >
      
    
      
        <a
          class="px-1 transition-transform hover:scale-125 hover:text-primary-700 dark:hover:text-primary-400"
          style="will-change:transform;"
          href="https://www.linkedin.com/in/eric-miller/"
          target="_blank"
          aria-label="Linkedin"
          rel="me noopener noreferrer"
          ><span class="icon relative inline-block px-1 align-text-bottom"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
</span></a
        >
      
    
  </div>

</div>
    </div>
  </div>


      
  
  <section class="flex flex-row flex-wrap justify-center pt-4 text-xl">
    
      
        <a
          class="m-1 inline-block min-w-[2.4rem] rounded bg-neutral-300 p-1 text-center text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
          href="https://www.facebook.com/sharer/sharer.php?u=http://bartolomeo.home:1313/posts/2025-09-07-llms-3/&amp;quote=Large%20Language%20Models,%20pt.%203:%20Context"
          title="Share on Facebook"
          aria-label="Share on Facebook"
          target="_blank"
          rel="noopener noreferrer"
          ><span class="icon relative inline-block px-1 align-text-bottom"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M504 256C504 119 393 8 256 8S8 119 8 256c0 123.78 90.69 226.38 209.25 245V327.69h-63V256h63v-54.64c0-62.15 37-96.48 93.67-96.48 27.14 0 55.52 4.84 55.52 4.84v61h-31.28c-30.8 0-40.41 19.12-40.41 38.73V256h68.78l-11 71.69h-57.78V501C413.31 482.38 504 379.78 504 256z"/></svg>
</span></a
        >
      
    
      
        <a
          class="m-1 inline-block min-w-[2.4rem] rounded bg-neutral-300 p-1 text-center text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
          href="https://x.com/intent/tweet/?url=http://bartolomeo.home:1313/posts/2025-09-07-llms-3/&amp;text=Large%20Language%20Models,%20pt.%203:%20Context"
          title="Post on X"
          aria-label="Post on X"
          target="_blank"
          rel="noopener noreferrer"
          ><span class="icon relative inline-block px-1 align-text-bottom"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/></svg>
</span></a
        >
      
    
      
        <a
          class="m-1 inline-block min-w-[2.4rem] rounded bg-neutral-300 p-1 text-center text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
          href="https://tootpick.org/#text=http://bartolomeo.home:1313/posts/2025-09-07-llms-3/%20Large%20Language%20Models,%20pt.%203:%20Context"
          title="Toot on Mastodon"
          aria-label="Toot on Mastodon"
          target="_blank"
          rel="noopener noreferrer"
          ><span class="icon relative inline-block px-1 align-text-bottom"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M433 179.11c0-97.2-63.71-125.7-63.71-125.7-62.52-28.7-228.56-28.4-290.48 0 0 0-63.72 28.5-63.72 125.7 0 115.7-6.6 259.4 105.63 289.1 40.51 10.7 75.32 13 103.33 11.4 50.81-2.8 79.32-18.1 79.32-18.1l-1.7-36.9s-36.31 11.4-77.12 10.1c-40.41-1.4-83-4.4-89.63-54a102.54 102.54 0 0 1-.9-13.9c85.63 20.9 158.65 9.1 178.75 6.7 56.12-6.7 105-41.3 111.23-72.9 9.8-49.8 9-121.5 9-121.5zm-75.12 125.2h-46.63v-114.2c0-49.7-64-51.6-64 6.9v62.5h-46.33V197c0-58.5-64-56.6-64-6.9v114.2H90.19c0-122.1-5.2-147.9 18.41-175 25.9-28.9 79.82-30.8 103.83 6.1l11.6 19.5 11.6-19.5c24.11-37.1 78.12-34.8 103.83-6.1 23.71 27.3 18.4 53 18.4 175z"/></svg>
</span></a
        >
      
    
      
        <a
          class="m-1 inline-block min-w-[2.4rem] rounded bg-neutral-300 p-1 text-center text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
          href="https://www.linkedin.com/shareArticle?mini=true&amp;url=http://bartolomeo.home:1313/posts/2025-09-07-llms-3/&amp;title=Large%20Language%20Models,%20pt.%203:%20Context"
          title="Share on LinkedIn"
          aria-label="Share on LinkedIn"
          target="_blank"
          rel="noopener noreferrer"
          ><span class="icon relative inline-block px-1 align-text-bottom"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
</span></a
        >
      
    
      
        <a
          class="m-1 inline-block min-w-[2.4rem] rounded bg-neutral-300 p-1 text-center text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
          href="mailto:?body=http://bartolomeo.home:1313/posts/2025-09-07-llms-3/&amp;subject=Large%20Language%20Models,%20pt.%203:%20Context"
          title="Send via email"
          aria-label="Send via email"
          target="_blank"
          rel="noopener noreferrer"
          ><span class="icon relative inline-block px-1 align-text-bottom"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M207.8 20.73c-93.45 18.32-168.7 93.66-187 187.1c-27.64 140.9 68.65 266.2 199.1 285.1c19.01 2.888 36.17-12.26 36.17-31.49l.0001-.6631c0-15.74-11.44-28.88-26.84-31.24c-84.35-12.98-149.2-86.13-149.2-174.2c0-102.9 88.61-185.5 193.4-175.4c91.54 8.869 158.6 91.25 158.6 183.2l0 16.16c0 22.09-17.94 40.05-40 40.05s-40.01-17.96-40.01-40.05v-120.1c0-8.847-7.161-16.02-16.01-16.02l-31.98 .0036c-7.299 0-13.2 4.992-15.12 11.68c-24.85-12.15-54.24-16.38-86.06-5.106c-38.75 13.73-68.12 48.91-73.72 89.64c-9.483 69.01 43.81 128 110.9 128c26.44 0 50.43-9.544 69.59-24.88c24 31.3 65.23 48.69 109.4 37.49C465.2 369.3 496 324.1 495.1 277.2V256.3C495.1 107.1 361.2-9.332 207.8 20.73zM239.1 304.3c-26.47 0-48-21.56-48-48.05s21.53-48.05 48-48.05s48 21.56 48 48.05S266.5 304.3 239.1 304.3z"/></svg>
</span></a
        >
      
    
  </section>


      
  
    
    
    
    <div class="pt-8">
      <hr class="border-dotted border-neutral-300 dark:border-neutral-600" />
      <div class="flex justify-between pt-3">
        <span>
          
            <a class="group flex" href="http://bartolomeo.home:1313/posts/2025-09-06-llms-2/">
              <span
                class="me-2 text-neutral-700 transition-transform group-hover:-translate-x-[2px] group-hover:text-primary-600 dark:text-neutral dark:group-hover:text-primary-400"
                ><span class="ltr:inline rtl:hidden">&larr;</span
                ><span class="ltr:hidden rtl:inline">&rarr;</span></span
              >
              <span class="flex flex-col">
                <span
                  class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500"
                  >Large Language Models, pt. 2: Safety and Hygiene</span
                >
                <span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400">
                  
                    <time datetime="2025-09-04 13:23:29 -0500 CDT">September 4, 2025</time>
                  
                </span>
              </span>
            </a>
          
        </span>
        <span>
          
            <a class="group flex text-right" href="http://bartolomeo.home:1313/posts/2025-09-05-llms-1/">
              <span class="flex flex-col">
                <span
                  class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500"
                  >Large Language Models, pt. 1: What are LLMs?</span
                >
                <span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400">
                  
                    <time datetime="2025-09-05 12:00:00 -0500 CDT">September 5, 2025</time>
                  
                </span>
              </span>
              <span
                class="ms-2 text-neutral-700 transition-transform group-hover:-translate-x-[-2px] group-hover:text-primary-600 dark:text-neutral dark:group-hover:text-primary-400"
                ><span class="ltr:inline rtl:hidden">&rarr;</span
                ><span class="ltr:hidden rtl:inline">&larr;</span></span
              >
            </a>
          
        </span>
      </div>
    </div>
  


      
    </footer>
  </article>

      </main>
      
        <div
          class="pointer-events-none absolute bottom-0 end-0 top-[100vh] w-12"
          id="to-top"
          hidden="true"
        >
          <a
            href="#the-top"
            class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 backdrop-blur hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400"
            aria-label="Scroll to top"
            title="Scroll to top"
          >
            &uarr;
          </a>
        </div>
      <footer class="py-10 print:hidden">
  
  
  <div class="flex items-center justify-between">
    <div>
      
      
        <p class="text-sm text-neutral-500 dark:text-neutral-400">
            &copy;
            2025
            Eric Miller
        </p>
      
      
      
        <p class="text-xs text-neutral-500 dark:text-neutral-400">
          
          
          Powered by <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500"
            href="https://gohugo.io/" target="_blank" rel="noopener noreferrer">Hugo</a> &amp; <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500" href="https://github.com/jpanther/congo" target="_blank" rel="noopener noreferrer">Congo</a>
        </p>
      
    </div>
    <div class="flex flex-row items-center">
      
      
      
      
        <div
          class="me-14 cursor-pointer text-sm text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400"
        >
          <button id="appearance-switcher-0" type="button" aria-label="appearance switcher">
            <div
              class="flex h-12 w-12 items-center justify-center dark:hidden"
              title="Switch to dark appearance"
            >
              <span class="icon relative inline-block px-1 align-text-bottom"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M32 256c0-123.8 100.3-224 223.8-224c11.36 0 29.7 1.668 40.9 3.746c9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3c9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480C132.1 480 32 379.6 32 256z"/></svg>
</span>
            </div>
            <div
              class="hidden h-12 w-12 items-center justify-center dark:flex"
              title="Switch to light appearance"
            >
              <span class="icon relative inline-block px-1 align-text-bottom"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M256 159.1c-53.02 0-95.1 42.98-95.1 95.1S202.1 351.1 256 351.1s95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347L446.1 255.1l63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7l-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89L164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6L12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256l-63.15 91.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7l19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109l109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69 0-127.1-57.31-127.1-127.1c0-70.69 57.31-127.1 127.1-127.1s127.1 57.3 127.1 127.1C383.1 326.7 326.7 383.1 256 383.1z"/></svg>
</span>
            </div>
          </button>
        </div>
      
    </div>
  </div>
  
  
</footer>

    </div>
  </body>
</html>
